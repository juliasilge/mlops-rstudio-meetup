---
title: "Version, deploy, and monitor your model with vetiver in R"
---

```{r}
#| echo: false
#| eval: false

## data from TidyTuesday: https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-13/readme.md

library(tidyverse)
theme_set(theme_light())
library(arrow)
scooby_raw <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-07-13/scoobydoo.csv')

scooby_raw %>%
  mutate(
    imdb = parse_number(imdb),
    year_aired = lubridate::year(date_aired)
  ) %>%
  filter(monster_amount > 0, !is.na(imdb)) %>%
  mutate(
    monster_real = case_when(
      monster_real == "FALSE" ~ "fake",
      TRUE ~ "real"
    ),
    monster_real = factor(monster_real)
  ) %>%
  select(monster_real, year_aired, imdb, title) %>%
  write_feather("scooby-do.arrow")

set.seed(2022)
tibble(
  date_aired = as.Date("2023-01-01") + 1:1e3,
  imdb = sample(seq(from = 5, to = 9, by = 0.2), size = 1e3, replace = TRUE),
  monster_real = sample(as.factor(c("fake", "real")), size = 1e3, replace = TRUE, prob = c(0.8, 0.2))
) %>%
  mutate(year_aired = lubridate::year(date_aired)) %>%
  slice_sample(n = 100)  %>%
  arrange(date_aired) %>%
  select(monster_real, date_aired, year_aired, imdb) %>%
  write_feather("scooby-validation.arrow")

```

## The MLOps cycle

![](https://vetiver.rstudio.com/images/ml_ops_cycle.png)

Data scientists have effective tools that they ‚ù§Ô∏è to:

-   collect data

-   prepare, manipulate, refine data

-   train models

There is a lack üò© of effective tools (especially open source) to:

-   put models into production

-   monitor model performance

-   trigger retraining

## What is vetiver? <https://vetiver.rstudio.com/>

> *Vetiver, the oil of tranquility, is used as a stabilizing ingredient in perfumery to preserve more volatile fragrances.*

The **goal** of vetiver is to provide fluent tooling to **version, deploy, and monitor** a trained model.

## Build a model

Let's build a model to predict which [Scooby Doo episodes](https://github.com/rfordatascience/tidytuesday/blob/master/data/2021/2021-07-13/readme.md) have a *real* monster and which have a *fake* monster. üëª

```{r}
#| message: false
library(tidyverse)
library(arrow)
scooby <- read_feather("scooby-do.arrow")

scooby
```

```{r}
#| message: false
library(tidymodels)
svm_spec <- svm_linear(mode = "classification")
scooby_rec <- 
  recipe(monster_real ~ year_aired + imdb, data = scooby) %>%
  step_normalize(all_numeric_predictors())
svm_fit <-
  workflow(scooby_rec, svm_spec) %>%
  fit(scooby)
```

Data scientists use tools they love for these steps, like the tidyverse, pandas, tidymodels, scikit-learn, etc.

## Version and deploy a model

Create a deployable model object:

```{r}
library(vetiver)
v <- vetiver_model(svm_fit, "scooby-doo")
v
```

Version and share the model:

```{r}
#| eval: false
library(pins)
model_board <- board_rsconnect() ## also support board_s3(), board_azure(), etc
model_board %>% vetiver_pin_write(v)
```

Document the model: <https://vetiver.rstudio.com/learn-more/model-card.html>

Deploy model as a REST API:

```{r}
library(plumber)
pr() %>%
  vetiver_api(v, debug = TRUE)
```

-   Deploy to Connect: <https://rstudio.github.io/vetiver-r/dev/reference/vetiver_deploy_rsconnect.html>

-   Deploy via Docker (after creating plumber file via `vetiver_write_plumber(model_board, "julia.silge/scooby-doo")`):

```{r}
#| eval: false
vetiver_write_docker(v)
```

Build the Docker container (from command line):

```{bash}
#| eval: false
docker build --platform linux/amd64 -t scooby-doo .
```

Run the Docker container (from command line):

```{bash}
#| eval: false
docker run --env-file .Renviron --rm -p 8000:8000 scooby-doo
```

## Predict from a model

Predict for remote vetiver model:

```{r}
#| eval: false
scooby_endpoint <- vetiver_endpoint("http://0.0.0.0:8000/predict")
scooby_endpoint
```

```{r}
new_episodes <- tidyr::crossing(
  year_aired = sample(1970:2000, size = 3),
  imdb = sample(5:9, size = 3)
)
new_episodes
```

```{r}
#| eval: false
predict(scooby_endpoint, new_episodes)
```

## Monitor your model

To monitor the statistical properties of your model over time, you will need new data with labels. Let's say that Scooby Doo airs more episodes starting this year:

```{r}
scooby_validation <- read_feather("scooby-validation.arrow")
scooby_validation
```

We can compute multiple metrics at once over a certain time aggregation.

### How does a model use time? ü§î

-   Your model **sometimes** uses date-time quantities as features for prediction (like these Scooby Doo episodes!).
-   Monitoring **always** involves a date-time quantity, not necessarily as a feature, but as a dimension along which you are monitoring.

```{r}
scooby_metrics <-
  augment(v, new_data = scooby_validation)  %>%
  vetiver_compute_metrics(date_aired, "year", monster_real, .pred_class)

scooby_metrics
```

```{r}
#| fig-width: 8
#| fig-height: 5
ggplot(scooby_metrics, aes(.index, .estimate, fill = .metric)) +
  geom_col(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~.metric, scales = "free") +
  labs(x = NULL, y = NULL)
```

Check out a [more realistic monitoring](https://colorado.rstudio.com/rsc/seattle-housing-dashboard/) example that uses the dashboard template in vetiver!
